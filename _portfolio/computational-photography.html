---
title: "Digital Image Forensics"
excerpt: "<div><p><img style='object-fit:scale-down; max-height: 150px; display: block; float: left; padding-right: 0.5em; padding-bottom: 0.5em;' src='/images/dip.png' width='300' height='150'></p>An algorithm that identifies which camera was used to capture an image using traces of information left intrinsically in the image, using filters, followed by a deep neural network on these filters. Detection of the source camera from a given image using noise, Fast Fourier Transformations, and other parameters, to train Deep Learning Models in an ensemble.</div>"
collection: portfolio
---
<style>
    .double-val-label {
	 /* display: table; */
	 font-family: 'Roboto', sans-serif;
	 margin: 0.4em auto;
     display: inline-block;
     
}
 .double-val-label>span {
	 background-color: #656565;
	 color: #ffffff;
	 display: table-cell;
	 font-size: 0.9em;
	 font-weight: 400;
	 line-height: 1;
	 padding: .3em .6em;
	 text-align: center;
	 vertical-align: baseline;
	 white-space: nowrap;
}
 .double-val-label>span:first-child {
	 border-radius: 0.25em;
}
 .double-val-label>span:nth-child(2) {
	 border-radius: .25em;
}
 .double-val-label>span.primary {
	 background-color: #337ab7;
}
 .double-val-label>span.success {
	 background-color: #5cb85c;
}
 .double-val-label>span.info {
	 background-color: #5bc0de;
}
 .double-val-label>span.warning {
	 background-color: #f0ad4e;
}
 .double-val-label>span.danger {
	 background-color: #d9534f;

 }
 .slideshow-container {
    max-width: 1000px;
    position: relative;
    margin: auto
}

.mySlides {
    display: none;
  height: 400px;
  border: solid 1px black;
     
}

.prev,
.next {
    cursor: pointer;
    position: absolute;
    top: 50%;
    width: auto;
    margin-top: -22px;
    padding: 16px;
    color: #222428;
    font-weight: bold;
    font-size: 30px;
    transition: .6s ease;
    border-radius: 0 3px 3px 0
}

.next {
    right: -50px;
    border-radius: 3px 3px 3px 3px
}

.prev {
    left: -50px;
    border-radius: 3px 3px 3px 3px
}

.prev:hover,
.next:hover {
    color: #f2f2f2;
    background-color: rgba(0, 0, 0, 0.8)
}

.text {
    color: #f2f2f2;
    font-size: 15px;
    padding-top: 12px;
  padding-bottom: 12px;
    position: absolute;
    bottom: 0;
    width: 100%;
    text-align: center;
    background-color: #222428
}

.numbertext {
    color: #f2f2f2;
    font-size: 12px;
    padding: 8px 12px;
    position: absolute;
    top: 0
}

.dot {
    cursor: pointer;
    height: 15px;
    width: 15px;
    margin: 0 2px;
    background-color: #bbb;
    border-radius: 50%;
    display: inline-block;
    transition: background-color .6s ease
}

.active,
.dot:hover {
    background-color: #717171
}
 
</style>
<div class="double-val-label"><span class="success">Computational Imaging</span></div>
<div class="double-val-label"><span class="primary">Computer Vision</span></div>
<div class="double-val-label"><span class="info">Fourier Transforms</span></div>
<div class="double-val-label"><span class="warning">Machine Learning</span></div>
<br>
Contender for the IEEE Signal Processing Cup 2018. An algorithm that identifies which camera was used to capture an image using traces of information left intrinsically in the image, using filters, followed by a deep neural network on these filters. Detection of the source camera from a given image using noise, Fast Fourier Transformations, and other parameters, to train Deep Learning Models in an ensemble. 
<br>
<br>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css" integrity="sha512-xh6O/CkQoPOWDdYTDqeRdPCVd1SpvCA9XXcUnZS2FmJNp1coAFzvtCN9BmamE+4aHK8yyUHUSCcJHgXloTyT2A==" crossorigin="anonymous" referrerpolicy="no-referrer" />
<a style="text-decoration: none;" target="_blank" href="https://github.com/grassknoted/Digital-Image-Forensics"><button type="button" class="btn btn-info" style="background-color: #6cc644; font-size: 1em;" ><i class="fa-brands fa-github"></i> GitHub</button></a>
<a style="text-decoration: none;" target="_blank" href="https://arxiv.org/abs/2210.09052"><button type="button" class="btn btn-primary" style="background-color: #bd1f36; font-size: 1em;" ><i class="fa-solid fa-file-pdf"></i> arXiv</button></a>
<br>
<br>
<strong>Technologies Used:</strong> Computational Imaging, Signal Processing, Deep Learning, Digital Signal Processing.
<br>
<br>
<strong>My Role:</strong> 
<ul>
    <li>Implemented Gray Level Dependency Matrix to get image statistics per camera.</li>
    <li>Dataset augmentation by introducing image manipulations.</li>
    <li>Implemented the Gallagher and Chen Algorithm  and Discrete Fourier Transforms to detect periodicity of camera noise.</li>
    <li>Experimented with ensemble learning to achieve the best accuracy.</li>
</ul>
<div style="text-align: center;"><h3>Project Gallery</h3></div>
<meta name="viewport" content="width=device-width, initial-scale=1">

<div class="slideshow-container" style="width: 600px; height: 400px;">
    <div class="slideshow-inner">
      <div class="mySlides fade">
        <img  src='/images/comp_image.png' style='width: 100%; max-width: 600px; max-height: 400px;' alt="sally lightfoot crab"/>
        <div class="text">Periodicity of noise patterns for difference Cameras</div>
      </div>
    </div>
    <a class="prev" onclick='plusSlides(-1)'>&#10094;</a>
    <a class="next" onclick='plusSlides(1)'>&#10095;</a>
</div>
<br/>
<div style='text-align: center;'>
    <span class="dot" onclick='currentSlide(1)'></span>
</div>
<script defer src="/assets/js/portfolio/11real-time-action-recognition.js"></script>