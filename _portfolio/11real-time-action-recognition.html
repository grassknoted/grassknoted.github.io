---
title: "Real-time Action Recognition" 
excerpt: "<div><p><img style='object-fit:scale-down; display: block; float: left; padding-right: 0.5em; padding-bottom: 0.5em; max-height: 150px;' src='/images/hand.png' width='300' height='150'></p>Action Recognition System for automated real-time hand sanitization auditing, working with real-world data from PES Institute of Medical Science and Research, primarily aimed to reduce bedside infections in hospitals, using a new approach to Action Recognition in videos.</div>"
collection: portfolio
---

<style>
    .double-val-label {
	 /* display: table; */
	 font-family: 'Roboto', sans-serif;
	 margin: 0.4em auto;
     display: inline-block;
     
}
 .double-val-label>span {
	 background-color: #656565;
	 color: #ffffff;
	 display: table-cell;
	 font-size: 0.9em;
	 font-weight: 400;
	 line-height: 1;
	 padding: .3em .6em;
	 text-align: center;
	 vertical-align: baseline;
	 white-space: nowrap;
}
 .double-val-label>span:first-child {
	 border-radius: 0.25em;
}
 .double-val-label>span:nth-child(2) {
	 border-radius: .25em;
}
 .double-val-label>span.primary {
	 background-color: #337ab7;
}
 .double-val-label>span.success {
	 background-color: #5cb85c;
}
 .double-val-label>span.info {
	 background-color: #5bc0de;
}
 .double-val-label>span.warning {
	 background-color: #f0ad4e;
}
 .double-val-label>span.danger {
	 background-color: #d9534f;

 }
 .slideshow-container {
    max-width: 1000px;
    position: relative;
    margin: auto
}

.mySlides {
    display: none;
  height: 400px;
  border: solid 1px black;
     
}

.prev,
.next {
    cursor: pointer;
    position: absolute;
    top: 50%;
    width: auto;
    margin-top: -22px;
    padding: 16px;
    color: #222428;
    font-weight: bold;
    font-size: 30px;
    transition: .6s ease;
    border-radius: 0 3px 3px 0
}

.next {
    right: -50px;
    border-radius: 3px 3px 3px 3px
}

.prev {
    left: -50px;
    border-radius: 3px 3px 3px 3px
}

.prev:hover,
.next:hover {
    color: #f2f2f2;
    background-color: rgba(0, 0, 0, 0.8)
}

.text {
    color: #f2f2f2;
    font-size: 15px;
    padding-top: 12px;
  padding-bottom: 12px;
    position: absolute;
    bottom: 0;
    width: 100%;
    text-align: center;
    background-color: #222428
}

.numbertext {
    color: #f2f2f2;
    font-size: 12px;
    padding: 8px 12px;
    position: absolute;
    top: 0
}

.dot {
    cursor: pointer;
    height: 15px;
    width: 15px;
    margin: 0 2px;
    background-color: #bbb;
    border-radius: 50%;
    display: inline-block;
    transition: background-color .6s ease
}

.active,
.dot:hover {
    background-color: #717171
}
 
</style>
<div class="double-val-label"><span class="success">Artificial Intelligence</span></div>
<div class="double-val-label"><span class="primary">Computer Vision</span></div>
<div class="double-val-label"><span class="info">ML4Health</span></div>
<div class="double-val-label"><span class="warning">Realtime Systems</span></div>
<br>
Used AI to address a real-world, potentially life-saving problem: minimizing Hospital Acquired Infections (HAI). HAIs are transmitted between patients due to improper hand sanitization of healthcare workers. In 2019, standard action recognition (AR) architectures struggled to differentiate between visually similar actions. Coincidentally, the actions of the hand sanitization steps are very similar in contrast to conventional AR benchmark data. As shown in~\cite{rl}, I addressed this drawback by including an object-level information stream using feature descriptors and extending the two-stream AR algorithm. Further, I optimized the system to work in real-time using network pruning and deployed it in local hospitals, leading to an 83% reduction in HAI. The project, currently patent-pending, received the Best Undergraduate Thesis award. For me, an important takeaway from this project was understanding the role of spatial, temporal, and object-level information in human and computer vision.
<br>
<br>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css" integrity="sha512-xh6O/CkQoPOWDdYTDqeRdPCVd1SpvCA9XXcUnZS2FmJNp1coAFzvtCN9BmamE+4aHK8yyUHUSCcJHgXloTyT2A==" crossorigin="anonymous" referrerpolicy="no-referrer" />
<a style="text-decoration: none;" target="_blank" href="https://github.com/grassknoted/Modified-Two-Stream-Fusion-for-Real-time-ActionRecognition"><button type="button" class="btn btn-info" style="background-color: #6cc644; font-size: 1em;" ><i class="fa-brands fa-github"></i> GitHub</button></a>
<a style="text-decoration: none;" target="_blank" href="https://arxiv.org/abs/2210.07400"><button type="button" class="btn btn-primary" style="background-color: #bd1f36; font-size: 1em;" ><i class="fa-solid fa-file-pdf"></i> arXiv</button></a>
<br>
<br>
<strong>Technologies Used:</strong> Python, Tensorflow, RaspberryPi, opencv.
<br>
<br>
<strong>My Role:</strong> 
<ul>
    <li>Led a team of 3 undergraduate student (including me).</li>
    <li>Designed the three-stream action recognition system.</li>
    <li>Manually recorded and created <a href="https://www.kaggle.com/datasets/realtimear/hand-wash-dataset">The Hand Wash Dataset</a>.</li>
    <li>Collected training data in hospital wards.</li>
    <li>Ran trials in hospital ICU and wards to guage doctor feedback.</li>
    <li>Developed the frame buffer for real-time processing.</li>
    <li>Neural Network pruning to ensure real-time inference.</li>
    <li>Built the setup entire system (hardware and case) with 3D printing for final product deployment.</li>
</ul>

<div style="text-align: center;"><h3>Project Gallery</h3></div>
<meta name="viewport" content="width=device-width, initial-scale=1">

<div class="slideshow-container" style="width: 600px; height: 400px;">
    <div class="slideshow-inner">
      <div class="mySlides fade">
        <img  src='/images/handwash_overview.png' style='width: 100%; max-width: 600px; max-height: 400px;' alt="sally lightfoot crab"/>
        <div class="text">System Overview</div>
      </div>
      <div class="mySlides fade">
        <img  src='/images/optical_flow.png' style='width: 100%; max-width: 600px; max-height: 400px;' alt="fighting nazca boobies"/>
        <div class="text">Dense Optical Flow</div>
      </div>
      <div class="mySlides fade">
        <img  src='/images/hospital_recording.png' style='width: 100%; max-width: 600px; max-height: 400px;' alt="otovalo waterfall"/>
        <div class="text">Hospital Deployment</div>
      </div>
      <div class="mySlides fade">
        <img  src='/images/home_recording.png' style='width: 100%; max-width: 600px; max-height: 400px;' alt="pelican"/>
        <div class="text">Recording the Dataset</div>
      </div>
      <div class="mySlides fade">
        <img  src='/images/hospital_deployment.png' style='width: 100%; max-width: 600px; max-height: 400px;' alt="pelican"/>
        <div class="text">Deployment of the System in the Hospital</div>
      </div>
      <div class="mySlides fade">
        <img  src='/images/handwash_steps.png' style='width: 100%; max-width: 600px; max-height: 400px;' alt="pelican"/>
        <div class="text">Steps of WHO Recommended Handwash Procedure</div>
      </div>
    </div>
    <a class="prev" onclick='plusSlides(-1)'>&#10094;</a>
    <a class="next" onclick='plusSlides(1)'>&#10095;</a>
</div>
<br/>
    
<div style='text-align: center;'>
    <span class="dot" onclick='currentSlide(1)'></span>
    <span class="dot" onclick='currentSlide(2)'></span>
    <span class="dot" onclick='currentSlide(3)'></span>
    <span class="dot" onclick='currentSlide(4)'></span>
    <span class="dot" onclick='currentSlide(5)'></span>
    <span class="dot" onclick='currentSlide(6)'></span>
</div>
<script defer src="/assets/js/portfolio/11real-time-action-recognition.js"></script>