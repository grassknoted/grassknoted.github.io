---
title: "Closed-loop optogenetic system for deep behavioral phenotyping"
collection: publications
permalink: /files/Closed-loop-optogenetic-system-for-deep-behavioral-phenotyping-Poster.pdf
excerpt: '<em>Presented at Society for Neuroscience (SfN) 2023 <strong>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css" integrity="sha512-xh6O/CkQoPOWDdYTDqeRdPCVd1SpvCA9XXcUnZS2FmJNp1coAFzvtCN9BmamE+4aHK8yyUHUSCcJHgXloTyT2A==" crossorigin="anonymous" referrerpolicy="no-referrer" />
<br>
<br>
<a style="text-decoration: none;" target="_blank" href="https://www.sfn.org/-/media/SfN/Documents/NEW-SfN/Meetings/Neuroscience-2023/Abstracts/Abstract-PDFs/SFN23_Abstracts-PDF-Posters_WED_PM.pdf#page=633" ><button onclick="event.stopPropagation();" style="background-color: #bd1f36;" type="button" class="btn btn-primary"><i class="fa-solid fa-file-pdf"></i> Abstract</button></a>'
date: 2023-01-26
authors: 'Remy Meir, <strong>Akash Nagaraj</strong>, Samir Samadov, Jaeson Jang, Thomas Serre, David Sheinberg, Jason Ritt, Diane Lipscombe'
paperurl: 'https://www.akashnagaraj.me/files/Closed-loop-optogenetic-system-for-deep-behavioral-phenotyping-Poster.pdf'
# citation: 'A. Nagaraj, M. Sood and G. Srinivasa, "Real-Time Automated Answer Scoring," 2018 IEEE 18th International Conference on Advanced Learning Technologies (ICALT), 2018, pp. 231-232, doi: 10.1109/ICALT.2018.00122.'
---
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-N13ZXFY26T"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-N13ZXFY26T');
</script>
<script>
var buttons = document.querySelectorAll("input[type=button]");
buttons.forEach(function(button) {
    button.addEventListener('click', function(event) {
        event.stopPropagation();
    });
});
</script>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-Zenh87qX5JnK2Jl0vWa8Ck2rdkQ2Bzep5IDxbcnCeuOxjzrPF/et3URy9Bv1WTRi" crossorigin="anonymous">
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-OERcA2EqjJCMA+/3y+gxIOqMEjwtxJY7qPCqsdltbNJuaOe923+mo//f6V8Qbsw3" crossorigin="anonymous"></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css" integrity="sha512-xh6O/CkQoPOWDdYTDqeRdPCVd1SpvCA9XXcUnZS2FmJNp1coAFzvtCN9BmamE+4aHK8yyUHUSCcJHgXloTyT2A==" crossorigin="anonymous" referrerpolicy="no-referrer" />

<div style="text-align: justify; text-justify: inter-word;"><strong>Abstract:</strong> The many successes of deep neural networks (DNNs) over the past decade have largely been driven by computational scale rather than insights from biological intelligence. While DNNs have nevertheless been surprisingly adept at explaining behavioral and neural recordings from humans, there is a growing number of reports indicating that DNNs are becoming progressively worse models of human vision as they improve on standard computer vision benchmarks. Here, we provide evidence that one path towards improving the alignment of DNNs with human vision is to train them with data and objective functions that more closely resemble those relied on by brains. We find that DNNs trained to capture the causal structure of large spatiotemporal object datasets learn generalizable object representations that exhibit smooth equivariance to 3-Dimensional (out-of-plane) variations in object pose and are predictive of human decisions and reaction times on popular psychophysics stimuli. Our work identifies novel data diets and objective functions that better align DNN vision with humans and can be easily scaled to generate the next generation of DNNs that behave as humans do.</div>
<br>
<div>
<a style="text-decoration: none;" target="_blank" href="https://www.akashnagaraj.me/files/Ecological_data_and_objectives.pdf"><button type="button" class="btn btn-primary" style="background-color: #bd1f36;"><i class="fa-solid fa-file-pdf"></i> Paper</button></a>

<!-- <a style="text-decoration: none;" target="_blank" href="https://www.kaggle.com/competitions/sp-society-camera-model-identification/data"><button type="button" class="btn btn-warning"><i class="fa-solid fa-database"></i> Data</button></a>
</div> -->
<br><br>
<strong>Citation:</strong> Nagaraj, A., Ashok, K. A., Linsley, D., Lewis, F. E., Zhou, P., and Serre, T., 2023. Ecological data and objectives align deep neural network representations with humans. Unifying Representations in Neural Models, Neural Information Processing Systems (NeurIPS) 2023.
